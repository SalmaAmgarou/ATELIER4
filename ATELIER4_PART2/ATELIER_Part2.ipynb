{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b5a243f-5865-405f-b04a-3cb6256dce14",
   "metadata": {},
   "source": [
    "# Part 2 Pytorch-Transformer (Text generation) with GPT2 Pre-trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a0ff92b-1694-43ba-b789-b623287b21d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 00:15:11.123570: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-26 00:15:11.123610: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-26 00:15:11.124673: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-26 00:15:11.131711: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-26 00:15:11.928822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel\n",
    "from datasets import Dataset as HFDataset\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "import warnings\n",
    "import psutil\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6437637-d27f-4695-9b7c-190a91d08e6c",
   "metadata": {},
   "source": [
    "### Loading only the column of description from that data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e51fa7-6acc-42a0-9a70-63eebec59e6b",
   "metadata": {},
   "source": [
    "I chose the dataset of Netflix Descriptions, the data has over 8800 lines, but we only trained with 1000 lines as my machine doesn't have the appropriate resources and hardware to train with a large dataset, and have effective results, trading epochs and time for amount of data in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b4d7e5-6d73-41bd-9fd1-6c4044051e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'netflix_titles.csv'\n",
    "descriptions = pd.read_csv(dataset_path)['description'][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d46990b9-1204-4a60-9d5d-c30c71f5d17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      As her father nears the end of his life, filmm...\n",
       "1      After crossing paths at a party, a Cape Town t...\n",
       "2      To protect his family from a powerful drug lor...\n",
       "3      Feuds, flirtations and toilet talk go down amo...\n",
       "4      In a city of coaching centers known to train I...\n",
       "                             ...                        \n",
       "995    In 1974, a rural town in Anatolia gets its fir...\n",
       "996    Truth and illusion blurs when a homeless amnes...\n",
       "997    Using innovative technology, this docuseries e...\n",
       "998    Journalists and fans await Ma Anand Sheela as ...\n",
       "999    A three-person crew on a mission to Mars faces...\n",
       "Name: description, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68b836-a04b-4b00-b313-173cab6ddece",
   "metadata": {},
   "source": [
    "### We use the gpu if available but in my case i have AMD which doesn't support ML and DL training and isn't compatible as requires NVIDEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483542f4-ce7a-4238-99bd-3a6a80b5c0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4693d-acb6-407a-862c-18ec340456ad",
   "metadata": {},
   "source": [
    "# Loading GPT2-medium which we will be using and the tokenizer from pytorch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "611f389e-c803-4337-9f9d-1df45f9f7caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 1024)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'gpt2-medium'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, bos_token='<|startoftext|>',\n",
    "                                          eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347eae1b-68b0-4e1d-b1c2-de31cd398141",
   "metadata": {},
   "source": [
    "### Defining max length of generated text to be the same as max in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ea6022-49b2-4358-9e92-abc61381b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the max length of generated description by looping through all descriptions in data and registering mac length\n",
    "max_length = max([len(tokenizer.encode(description)) for description in descriptions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8bc365-a45b-46ac-815a-b9dd069361fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class for Netflix descriptions\n",
    "class NetflixDataset(Dataset):\n",
    "    def __init__(self, txt_list, tokenizer, max_length):\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.labels = []\n",
    "\n",
    "        for txt in txt_list:\n",
    "            # Tokenize each description and store input IDs and attention masks\n",
    "            encodings_dict = tokenizer('' + txt + '', truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return a specific sample from the dataset\n",
    "        return self.input_ids[idx], self.attn_masks[idx]\n",
    "\n",
    "# Create an instance of the NetflixDataset class\n",
    "dataset = NetflixDataset(descriptions, tokenizer, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e38fab-d2c0-417d-9ab0-a3064a551704",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(dataset))\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9edfd57-2694-410d-b921-d0f45d06ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine available memory\n",
    "available_memory = psutil.virtual_memory().available / (1024 ** 3)  # Convert bytes to GB\n",
    "\n",
    "# Calculate a reasonable batch size (this is an estimation, adjust based on actual usage)\n",
    "# Here, we use a conservative estimate of 1GB per batch element as a starting point\n",
    "# Adjust the memory per element based on your specific model and input size\n",
    "memory_per_element = 1.0  # GB\n",
    "initial_batch_size = int(available_memory // memory_per_element // 2)  # Divide by 2 for safety margin\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './results',\n",
    "    num_train_epochs = 8,\n",
    "    learning_rate = 1e-4,\n",
    "    logging_steps = 10,\n",
    "    per_device_train_batch_size =5,\n",
    "    load_best_model_at_end = False,\n",
    "    per_device_eval_batch_size=initial_batch_size,\n",
    "    logging_dir ='./logs',\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e7eb595-c06c-4cd6-8d06-d825549ff234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a Trainer object and train the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=lambda data: {\n",
    "        'input_ids': torch.stack([f[0] for f in data]),\n",
    "        'attention_mask': torch.stack([f[1] for f in data]),\n",
    "        'labels': torch.stack([f[0] for f in data])\n",
    "    }\n",
    ")\n",
    "\n",
    "# trainer.train()\n",
    "# model.save_pretrained('./saved_model')\n",
    "# tokenizer.save_pretrained('./saved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f360e51-1fa3-458e-9048-dab7a7c8673f",
   "metadata": {},
   "source": [
    "We commented the previous lines because the models was already trained and saved and it took 24hours to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58ac627e-4016-47f5-bb30-94533fca5d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to choose a token from the top n probabilities\n",
    "import numpy as np\n",
    "def choose_from_top(probs, n=5):\n",
    "    ind = np.argpartition(probs, -n)[-n:]\n",
    "    top_prob = probs[ind]\n",
    "    top_prob = top_prob / np.sum(top_prob) # normalize\n",
    "    choice = np.random.choice(n, 1, p=top_prob)\n",
    "    token_id = ind[choice][0]\n",
    "    return int(token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a212b9c9-8bd6-4c58-9d8d-685880043305",
   "metadata": {},
   "source": [
    "## Loading already trained and saved model beforehand to evaluate and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ffab2a1-dd52-4363-b3b3-2e6acd407f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('./saved_model')\n",
    "model = GPT2LMHeadModel.from_pretrained('./saved_model').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a77c0-fe84-4cf4-8880-af2fd6373bbb",
   "metadata": {},
   "source": [
    "# Function of text generation with saved and trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b239d238-9bdc-465d-9d9d-b35360e2f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=80):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_length=max_length,\n",
    "        do_sample=True,\n",
    "        top_k=70,\n",
    "        temperature=3.0,\n",
    "        num_beams=5,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdf7807-8cba-4c4a-b46c-cdd432457e22",
   "metadata": {},
   "source": [
    "# Interface to test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14135f5e-a0ce-4874-8102-344cfaf8e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to handle the button click\n",
    "def on_generate_button_clicked(b):\n",
    "    prompt = prompt_textbox.value\n",
    "    generated_text = generate_text(prompt)\n",
    "    output_textbox.value = generated_text\n",
    "\n",
    "# Create the widgets\n",
    "prompt_textbox = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter your prompt here...',\n",
    "    description='Prompt:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='100%', height='100px')\n",
    ")\n",
    "\n",
    "generate_button = widgets.Button(\n",
    "    description='Generate Text',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Click to generate text',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "output_textbox = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Generated text will appear here...',\n",
    "    description='Output:',\n",
    "    disabled=True,\n",
    "    layout=widgets.Layout(width='100%', height='200px')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa72eaa7-bc13-4984-956d-471b31a71b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e644e55e134c7c8493653725d2eb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Prompt:', layout=Layout(height='100px', width='100%'), placeholder='Enter your…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d29ac1a14d04bdcade0cd5f15ab50c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Generate Text', icon='check', style=ButtonStyle(), tooltip='Click to …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3183d2aa90b4eb99a03854092248147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Output:', disabled=True, layout=Layout(height='200px', width='100%'), placehol…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the button click event\n",
    "generate_button.on_click(on_generate_button_clicked)\n",
    "\n",
    "# Display the interface\n",
    "display(prompt_textbox, generate_button, output_textbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c10e7-588d-4856-88c4-3c206c5e53c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
